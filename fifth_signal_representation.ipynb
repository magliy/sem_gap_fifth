{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная \"представление сигнала в различных пространствах\"\n",
    "\n",
    "Лабораторная состоит из гайда по использованию преобразований Фурье и вейвлет на Python и 3 заданий:\n",
    "\n",
    "* [Задание 1](#Задание-1.) - подобрать изображение, чтобы на спектре была окружность;\n",
    "\n",
    "* [Задание 2](#Задание-2.) - \"frame extrapolation\";\n",
    "\n",
    "* [Задание 3](#Задание-3.) - вейвлеты.\n",
    "\n",
    "*В этом ноутбуке изначально опущены результаты исполнения кода. Рекомендуется запускать (Shift+Enter) ячейки по мере просмотра документа*\n",
    "\n",
    "Сначала рекомендуется ознакомиться с гайдом, после чего выполнять задания.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Используемые модули\n",
    "\n",
    "Обновим пакетный менеджер pip, чтобы корректно уставить необходимые модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# При необходимости добавляйте опцию --user\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим необходимые модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключим модули, которые пригодятся в мини-лабораторной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pywt\n",
    "import pywt.data\n",
    "\n",
    "from imageio import imread, imsave\n",
    "\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "from save_answer import add_to_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление \"лишней\" информации\n",
    "\n",
    "Посмотрим на преобразование Фурье от картинки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(os.path.join('images', 'cube.jpg'))\n",
    "\n",
    "f = np.fft.fft2(rgb2gray(img))  # вычисляем 2D-FFT для изображения\n",
    "fshift = np.fft.fftshift(f)     # переупорядочим значения, чтобы 0 частота была в центре\n",
    "spectrum = 100 * np.log(np.abs(fshift))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6))\n",
    "ax[0].set_title('Input Image')\n",
    "ax[1].set_title('Magnitude Spectrum (Shift + Log)')\n",
    "ax[2].set_title('Reconstructed image')\n",
    "\n",
    "ax[0].imshow(img, cmap = 'gray')\n",
    "ax[1].imshow(spectrum, cmap = 'gray')\n",
    "\n",
    "transformed_fshift = fshift.copy()\n",
    "transformed_fshift[0:400, 0:100] = 0  # удалим куски, не содержащие светлых прямых на спектре, это не повлияет на рёбра куба\n",
    "transformed_fshift[600:900, 800:1000] = 0\n",
    "inv = np.fft.ifft2(np.fft.ifftshift(transformed_fshift)).real  # восстановим изображение обратным преобразованием\n",
    "ax[2].imshow(inv, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "Подберите такое изображение, чтобы на спектре была окружность.\n",
    "\n",
    "Изображение можно искусственно сгенерировать (к примеру, составить подходящий `numpy`-массив). В таком случае сначала сохраните исходное изображение в репозиторий, а потом прочитайте его из этого файла в переменную `task_1_image` - это нужно для удобства проверки, чтобы `answers.json` указывал путь до исходного изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_image = '<your image>'\n",
    "# img_2 = imread(os.path.join('images', task_1_image))\n",
    "\n",
    "\n",
    "plt.imshow(100 * np.log(np.abs(np.fft.fftshift(np.fft.fft2(rgb2gray(rgba2rgb(img_2)))))), cmap='gray')\n",
    "task_1_result = os.path.join('images', 'task_1.png')\n",
    "plt.savefig(task_1_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забудьте сохранить результат, выполнив ячейку ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_answer(\n",
    "    \"task_1\",\n",
    "    {\n",
    "        \"source_image\": task_1_image,\n",
    "        \"result_image\": task_1_result,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Усиление движений\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "Ниже приведён код, создающий два изображения (белые квадраты на чёрном фоне). Представьте, что это фрагмент видеозаписи, в которой квадрат движется из левого верхнего угла в правый нижний по прямой. Нам представлены только два соседних кадра (`frame_a` и `frame_b`), по ним требуется предсказать третий кадр `frame_c` (следующий за `frame_b` через промежуток времени, равный промежутку между `frame_a` и `frame_b`) *- примитивный вариант задачи \"frame extrapolation\"*.\n",
    "\n",
    "Будем решать задачу следующим образом: применим к изображениям преобразование Фурье, найдём амплитуду и фазу сигнала каждого кадра. По ним определим амплитуду и фазу сигнала искомого кадра `frame_c` (они должны как-то зависеть от амплитуд и фаз `frame_a` и `frame_b`, **как – решать вам**) и далее реконструируем искомое изображение.\n",
    "\n",
    "Вам в задании требуется изменить **две строки**, отмеченных знаком `(!)` в комментариях, так, чтобы реконструируемый кадр `frame_c` соответствовал описанию (белый квадрат должен оказаться в правом нижнем углу, с координатами центра примерно (75, 75)).\n",
    "\n",
    "*Данное решение приведено только как интересный пример. На самом деле задачу прогнозирования кадров, как и интерполирования (создания slow motion), обычно решают с помощью нахождения <u>оптического потока</u> в явном виде*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код генерации первых двух изображений\n",
    "canvas = np.zeros((100, 100))\n",
    "frame_a = canvas.copy()\n",
    "frame_b = canvas.copy()\n",
    "\n",
    "frame_a[20:30, 20:30] = 1.0  # \"Рисуем\" квадрат на первом изображении\n",
    "frame_b[44:55, 45:55] = 1.0  # \"Рисуем\" квадрат на втором изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перевод изображений в частотное пространство\n",
    "f_a = np.fft.fftshift(np.fft.fft2(frame_a))\n",
    "f_b = np.fft.fftshift(np.fft.fft2(frame_b))\n",
    "\n",
    "# получение амплитуд и фаз сигналов\n",
    "magnitude_a = np.abs(f_a)\n",
    "magnitude_b = np.abs(f_b)\n",
    "phase_a = np.angle(f_a)\n",
    "phase_b = np.angle(f_b)\n",
    "\n",
    "# само задание - поменять следующие две строки:\n",
    "magnitude_c = magnitude_a # (!) возможно, надо поменять эту строку\n",
    "phase_c = phase_a  # (!) и/или эту\n",
    "\n",
    "# получение нового сигнала в частотном пространстве из модуля и аргумента\n",
    "f_c = magnitude_c * np.exp(1.0j * phase_c)\n",
    "# перевод в исходное пространство\n",
    "frame_c = np.fft.ifft2(np.fft.ifftshift(f_c)).real\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].imshow(frame_a, cmap='gray')\n",
    "ax[1].imshow(frame_b, cmap='gray')\n",
    "ax[2].imshow(frame_c, cmap='gray')\n",
    "\n",
    "task_2_result = os.path.join('images', 'task_2.png')\n",
    "plt.savefig(task_2_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забудьте сохранить результат, выполнив ячейку ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_answer(\n",
    "    \"task_2\",\n",
    "    {\n",
    "        \"result_image\": task_2_result,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Вейвлеты\n",
    "\n",
    "Вейвлет - любой сигнал, задающий локальное преобразованиие с нулевым средним. Амплитуда сигнала вейвлета сначала 0, затем произвольная с нулевым средним (интеграл амплитуды по числовой оси равен 0), затем снова 0. Здесь слово \"сигнал\" можно заменить словом \"функция\".\n",
    "Примерами вейвлетов являются фильтры Соболя, Превитта и другие (рассматривавшиеся при поиске границ изображения).\n",
    "\n",
    "Вейвлет-преобразование представляет собой свертку с фильтром, задаваемым вейвлетом.\n",
    "\n",
    "Вейвлет-разложениие - разложение по набору масштабированных и смещенных вейвлетов (версий одной базовой функции-фильтра вейвлета). Оно позволяет разложить одномерный кусочно-непрерывный сигнал с конечным числом точек разрыва на конечное число составляющих. Также вейвлет-разложение может быть удобно для сжатия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведен код, загружающий избражение и применяющий к нему фильтры [вейвлета Мейера](http://wavelets.pybytes.com/wavelet/dmey/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка изображения\n",
    "original = pywt.data.camera()\n",
    "\n",
    "def apply_filters(image):\n",
    "    one, (two, three, four) = pywt.dwt2(image, 'dmey')  # Применение фильтров\n",
    "    fig = plt.figure(figsize=(16, 3))\n",
    "    titles = ('original', 'one', 'two', 'three', 'four')\n",
    "    for i, a in enumerate((image, one, two, three, four)):\n",
    "        ax = fig.add_subplot(1, 5, i + 1)\n",
    "        ax.imshow(a, interpolation=\"nearest\", cmap='gray')\n",
    "        ax.set_title(titles[i], fontsize=12)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "apply_filters(original)\n",
    "        \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "Подберите либо сконструируйте входное изображение, при котором результаты применения:\n",
    "1. `one` и `two` совпадают$^*$\n",
    "2. `three` и `four` совпадают$^*$\n",
    "3. `one` и `three` различаются$^*$\n",
    "\n",
    "$^*$ - сравниваются \"нормализованные\" результаты: в полученных `numpy`-массивах сначала \"пиксели\" картинок делятся на максимальные значения внутри каждой картинки, после чего нормализованные результаты сравниваются. Вовсе не обязательно, чтобы, например, `one` и `two` совпадали попиксельно до применения нормализации, но обязательно, чтобы совпадали с учётом нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_3 = <your array>  # Сгенерируйте подходящее изображение\n",
    "# img_3 = imread(os.path.join('images', <your image>))  # Или подберите картинку и загрузите её\n",
    "img_3 = rgb2gray(img_3) if len(img_3.shape) == 3 and img_3.shape[-1] == 3 else img_3 # Перевод в чёрно-белый формат (если нужно)\n",
    "\n",
    "def check(image):\n",
    "    # Эта проверка нужна, чтобы убедиться, что условия выполнены, после визуальной проверки\n",
    "    one, (two, three, four) = pywt.dwt2(image, 'dmey')  # Применение фильтров\n",
    "    normalized = tuple(map(lambda arr: arr / arr.max(), (one, two, three, four)))\n",
    "    \n",
    "    def arrs_equal(arr1, arr2):\n",
    "        return (arr1 - arr2).sum() < 1e-8\n",
    "    \n",
    "    cond_1 = arrs_equal(normalized[0], normalized[1])\n",
    "    cond_2 = arrs_equal(normalized[2], normalized[3])\n",
    "    cond_3 = not arrs_equal(normalized[0], normalized[2])\n",
    "    \n",
    "    for i, cond in enumerate((cond_1, cond_2, cond_3)):\n",
    "        if not cond:\n",
    "            print(f'Условие {i + 1} не выполнено!')\n",
    "    print('Все условия выполнены!' if cond_1 and cond_2 and cond_3 else 'Подберите/сгенерируйте другое изображение')\n",
    "    \n",
    "check(img_3)\n",
    "apply_filters(img_3)\n",
    "\n",
    "task_3_result = os.path.join('images', 'task_3.png')\n",
    "fig.tight_layout()\n",
    "plt.savefig(task_3_result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забудьте сохранить результат, выполнив ячейку ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_answer(\n",
    "    \"task_3\",\n",
    "    {\n",
    "        \"result_image\": task_3_result,\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
